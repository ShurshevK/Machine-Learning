{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ea268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a8a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "import xlrd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "sns.set_style('white')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from time import time\n",
    "import matplotlib.ticker as tkr\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "%matplotlib inline\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b85267",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams[\"figure.figsize\"] = 20,20\n",
    "\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, \"%m/%d/%y\")\n",
    "\n",
    "df = pd.read_excel(\n",
    "     os.path.join(\"test.xlsx\"),sheet_name=\"Data\", engine='openpyxl', parse_dates=[0], date_parser = parser\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2955e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"Severity\",'Case ID', \"Status\",\"Total\" ],axis = 1, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby([\"Entered on\"], as_index = True).mean()\n",
    "df = df.rename(columns={'Resolution Time': 'value'})\n",
    "df = df.fillna(0)\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b09de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "def plot_dataset(df, title):\n",
    "    data = []\n",
    "    value = go.Scatter(\n",
    "        x=df.index,\n",
    "        y=df.iloc[:,0],\n",
    "        mode=\"lines\",\n",
    "        name=\"incidents\",\n",
    "        marker=dict(),\n",
    "        text=df.index,\n",
    "        line=dict(color=\"rgba(1,0,1, 0.3)\"),\n",
    "        \n",
    "        \n",
    "        \n",
    "    )\n",
    "    data.append(value)\n",
    "        \n",
    "\n",
    "    layout = dict(\n",
    "        title=title,\n",
    "        xaxis=dict(title=\"Date\", ticklen=5, zeroline=False),\n",
    "        yaxis=dict(title=\"Incidents\", ticklen=5, zeroline=False),\n",
    "    )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(df, \"Number of Incidents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c449ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "%matplotlib inline\n",
    "import xlrd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "import seaborn as sns\n",
    "sns.set_context(\"paper\", font_scale=1.3)\n",
    "sns.set_style('white')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from time import time\n",
    "import matplotlib.ticker as tkr\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "%matplotlib inline\n",
    "import math\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device}\" \" is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3058f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "close_data = df['value'].values\n",
    "close_data = close_data.reshape((-1,1))\n",
    "\n",
    "split_percent = 0.80\n",
    "split = int(split_percent*len(close_data))\n",
    "\n",
    "X_train = close_data[:split]\n",
    "y_test = close_data[split:]\n",
    "\n",
    "\n",
    "print(len(X_train))\n",
    "print(len(close_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592f904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler\n",
    "\n",
    "def get_scaler(scaler):\n",
    "    scalers = {\n",
    "        \"minmax\": MinMaxScaler,\n",
    "        \"standard\": StandardScaler,\n",
    "        \"maxabs\": MaxAbsScaler,\n",
    "        \"robust\": RobustScaler,\n",
    "    }\n",
    "    return scalers.get(scaler.lower())()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195a210",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = get_scaler('minmax')\n",
    "\n",
    "scaler = scaler.fit(X_train)\n",
    "\n",
    "train_data = scaler.transform(X_train)\n",
    "\n",
    "test_data = scaler.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489fb94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    xs = []\n",
    "    ys = []\n",
    "\n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        x = data[i:(i+seq_length)]\n",
    "        y = data[i+seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "\n",
    "    return np.array(xs), np.array(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59464114",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 5\n",
    "X_train, y_train = create_sequences(train_data, seq_length)\n",
    "X_test, y_test = create_sequences(test_data, seq_length)\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e961eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
    "        \"\"\"The __init__ method that initiates an RNN instance.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): The number of nodes in the input layer\n",
    "            hidden_dim (int): The number of nodes in each layer\n",
    "            layer_dim (int): The number of layers in the network\n",
    "            output_dim (int): The number of nodes in the output layer\n",
    "            dropout_prob (float): The probability of nodes being dropped out\n",
    "\n",
    "        \"\"\"\n",
    "        super(RNNModel, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # RNN layers\n",
    "        self.rnn = nn.RNN(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward method takes input tensor x and does forward propagation\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor of the shape (batch size, sequence length, input_dim)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor of the shape (batch size, output_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Forward propagation by passing in the input and hidden state into the model\n",
    "        out, h0 = self.rnn(x, h0.detach())\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "\n",
    "  def __init__(self, n_features, n_hidden, seq_len, n_layers=2):\n",
    "    super(LSTMModel, self).__init__()\n",
    "\n",
    "    self.n_hidden = n_hidden\n",
    "    self.seq_len = seq_len\n",
    "    self.n_layers = n_layers\n",
    "\n",
    "    self.lstm = nn.LSTM(\n",
    "      input_size=n_features,\n",
    "      hidden_size=n_hidden,\n",
    "      num_layers=n_layers,\n",
    "      dropout=0.5\n",
    "    )\n",
    "\n",
    "    self.linear = nn.Linear(in_features=n_hidden, out_features=1)\n",
    "\n",
    "  def reset_hidden_state(self):\n",
    "    self.hidden = (\n",
    "        torch.zeros(self.n_layers, self.seq_len, self.n_hidden),\n",
    "        torch.zeros(self.n_layers, self.seq_len, self.n_hidden)\n",
    "    )\n",
    "\n",
    "  def forward(self, sequences):\n",
    "    lstm_out, self.hidden = self.lstm(\n",
    "      sequences.view(len(sequences), self.seq_len, -1),\n",
    "      self.hidden\n",
    "    )\n",
    "    last_time_step = \\\n",
    "      lstm_out.view(self.seq_len, len(sequences), self.n_hidden)[-1]\n",
    "    y_pred = self.linear(last_time_step)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829cdf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    \"\"\"GRUModel class extends nn.Module class and works as a constructor for GRUs.\n",
    "\n",
    "       GRUModel class initiates a GRU module based on PyTorch's nn.Module class.\n",
    "       It has only two methods, namely init() and forward(). While the init()\n",
    "       method initiates the model with the given input parameters, the forward()\n",
    "       method defines how the forward propagation needs to be calculated.\n",
    "       Since PyTorch automatically defines back propagation, there is no need\n",
    "       to define back propagation method.\n",
    "\n",
    "       Attributes:\n",
    "           hidden_dim (int): The number of nodes in each layer\n",
    "           layer_dim (str): The number of layers in the network\n",
    "           gru (nn.GRU): The GRU model constructed with the input parameters.\n",
    "           fc (nn.Linear): The fully connected layer to convert the final state\n",
    "                           of GRUs to our desired output shape.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
    "        \"\"\"The __init__ method that initiates a GRU instance.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): The number of nodes in the input layer\n",
    "            hidden_dim (int): The number of nodes in each layer\n",
    "            layer_dim (int): The number of layers in the network\n",
    "            output_dim (int): The number of nodes in the output layer\n",
    "            dropout_prob (float): The probability of nodes being dropped out\n",
    "\n",
    "        \"\"\"\n",
    "        super(GRUModel, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.layer_dim = layer_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # GRU layers\n",
    "        self.gru = nn.GRU(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"The forward method takes input tensor x and does forward propagation\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): The input tensor of the shape (batch size, sequence length, input_dim)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The output tensor of the shape (batch size, output_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Forward propagation by passing in the input and hidden state into the model\n",
    "        out, _ = self.gru(x, h0.detach())\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d080c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model, model_params):\n",
    "    models = {\n",
    "        \"rnn\": RNNModel,\n",
    "        \"lstm\": LSTMModel,\n",
    "        \"gru\": GRUModel,\n",
    "    }\n",
    "    return models.get(model.lower())(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de0cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "  model,\n",
    "  train_data,\n",
    "  train_labels,\n",
    "  test_data=None,\n",
    "  test_labels=None\n",
    "):\n",
    "        \n",
    "          loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "          optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "          num_epochs = 60\n",
    "          train_hist = np.zeros(num_epochs)\n",
    "          test_hist = np.zeros(num_epochs)\n",
    "          for t in range(num_epochs):\n",
    "            model.reset_hidden_state()\n",
    "            y_pred = model(X_train)\n",
    "            loss = loss_fn(y_pred.float(), y_train)\n",
    "            if test_data is not None:\n",
    "              with torch.no_grad():\n",
    "                y_test_pred = model(X_test)\n",
    "                test_loss = loss_fn(y_test_pred.float(), y_test)\n",
    "              test_hist[t] = test_loss.item()\n",
    "              if t % 10 == 0:\n",
    "                print(f'Epoch {t} train loss: {loss.item()} test loss: {test_loss.item()}')\n",
    "            elif t % 10 == 0:\n",
    "              print(f'Epoch {t} train loss: {loss.item()}')\n",
    "            train_hist[t] = loss.item()\n",
    "            optimiser.zero_grad()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "          return model.eval(), train_hist, test_hist\n",
    "\n",
    "def plot_losses(train_hist,test_his):\n",
    "    plt.plot(train_hist, label=\"Training loss\")\n",
    "    plt.plot(test_hist, label=\"Test loss\")\n",
    "    plt.ylim((0, 5))\n",
    "    plt.legend();\n",
    "        \n",
    "plot_losses(train_hist,test_his)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "model = LSTMModel(\n",
    "  n_features=1, \n",
    "  n_hidden=64, \n",
    "  seq_len=seq_length, \n",
    "  n_layers=2\n",
    ")\n",
    "model, train_hist, test_hist = train_model(\n",
    "  model, \n",
    "  X_train, \n",
    "  y_train, \n",
    "  X_test, \n",
    "  y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86abe2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-029b56d2cb14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m   \u001b[0mtest_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#predicting daily cases\n",
    "with torch.no_grad():\n",
    "  test_seq = X_test[:1]\n",
    "  preds = []\n",
    "  for _ in range(len(X_test)):\n",
    "    y_test_pred = model(test_seq)\n",
    "    pred = torch.flatten(y_test_pred).item()\n",
    "    preds.append(pred)\n",
    "    new_seq = test_seq.numpy().flatten()\n",
    "    new_seq = np.append(new_seq, [pred])\n",
    "    new_seq = new_seq[1:]\n",
    "    test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse the data\n",
    "true_cases = scaler.inverse_transform(\n",
    "    np.expand_dims(y_test.flatten().numpy(), axis=0)\n",
    ").flatten()\n",
    "\n",
    "predicted_cases = scaler.inverse_transform(\n",
    "  np.expand_dims(preds, axis=0)\n",
    ").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fdc138",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "  daily_cases.index[:len(train_data)], \n",
    "  scaler.inverse_transform(train_data).flatten(),\n",
    "  label='Historical Daily Cases'\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "  daily_cases.index[len(train_data):len(train_data) + len(true_cases)], \n",
    "  true_cases,\n",
    "  label='Real Daily Cases'\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "  daily_cases.index[len(train_data):len(train_data) + len(true_cases)], \n",
    "  predicted_cases, \n",
    "  label='Predicted Daily Cases'\n",
    ")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b1d5a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MinMaxScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c649520e3996>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mall_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler = scaler.fit(df)\n",
    "\n",
    "all_data = scaler.transform(df)\n",
    "\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all = create_sequences(all_data, seq_length)\n",
    "\n",
    "X_all = torch.from_numpy(X_all).float()\n",
    "y_all = torch.from_numpy(y_all).float()\n",
    "\n",
    "model = CoronaVirusPredictor(\n",
    "  n_features=1, \n",
    "  n_hidden=512, \n",
    "  seq_len=seq_length, \n",
    "  n_layers=2\n",
    ")\n",
    "model, train_hist, _ = train_model(model, X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb2126",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAYS_TO_PREDICT = 12\n",
    "\n",
    "with torch.no_grad():\n",
    "  test_seq = X_all[:1]\n",
    "  preds = []\n",
    "  for _ in range(DAYS_TO_PREDICT):\n",
    "    y_test_pred = model(test_seq)\n",
    "    pred = torch.flatten(y_test_pred).item()\n",
    "    preds.append(pred)\n",
    "    new_seq = test_seq.numpy().flatten()\n",
    "    new_seq = np.append(new_seq, [pred])\n",
    "    new_seq = new_seq[1:]\n",
    "    test_seq = torch.as_tensor(new_seq).view(1, seq_length, 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f9bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cases = scaler.inverse_transform(\n",
    "  np.expand_dims(preds, axis=0)\n",
    ").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e089c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_index = pd.date_range(\n",
    "  start=daily_cases.index[-1],\n",
    "  periods=DAYS_TO_PREDICT + 1,\n",
    "  closed='right'\n",
    ")\n",
    "\n",
    "predicted_cases = pd.Series(\n",
    "  data=predicted_cases,\n",
    "  index=predicted_index\n",
    ")\n",
    "\n",
    "plt.plot(predicted_cases, label='Predicted Daily Cases')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a620264",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(daily_cases, label='Historical Daily Cases')\n",
    "plt.plot(predicted_cases, label='Predicted Daily Cases')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446b92b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_dim = len(X_train.columns)\n",
    "output_dim = 1\n",
    "hidden_dim = 32\n",
    "layer_dim = 2\n",
    "batch_size = 32\n",
    "dropout = 0.2\n",
    "n_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "model_params = {'input_dim': input_dim,\n",
    "                'hidden_dim' : hidden_dim,\n",
    "                'layer_dim' : layer_dim,\n",
    "                'output_dim' : output_dim,\n",
    "                'dropout_prob' : dropout}\n",
    "\n",
    "model = get_model('lstm', model_params)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)\n",
    "opt.plot_losses()\n",
    "\n",
    "predictions, values = opt.evaluate(\n",
    "    test_loader_one,\n",
    "    batch_size=1,\n",
    "    n_features=input_dim\n",
    ")\n",
    "test_loader_iter = iter(test_loader)\n",
    "*_, (X, y) = test_loader_iter\n",
    "forecast = forecast(X, y, batch_size=batch_size, n_features=input_dim, n_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a984a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def inverse_transform(scaler, df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = scaler.inverse_transform(df[col])\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_predictions(predictions, values, df_test, scaler):\n",
    "    vals = np.concatenate(values, axis=0).ravel()\n",
    "    preds = np.concatenate(predictions, axis=0).ravel()\n",
    "    df_result = pd.DataFrame(data={\"value\": vals, \"prediction\": preds}, index=df_test.head(len(vals)).index)\n",
    "    df_result = df_result.sort_index()\n",
    "    df_result = inverse_transform(scaler, df_result, [[\"value\", \"prediction\"]])\n",
    "    return df_result\n",
    "\n",
    "\n",
    "df_result = format_predictions(predictions, values, X_test, scaler)\n",
    "df_result\n",
    "# df_result.to_excel('Tablea_Motion_Chart.xlsx', sheet_name='new_sheet_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f141ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "\n",
    "def plot_predictions(df_result, df_baseline):\n",
    "    data = []\n",
    "    \n",
    "    value = go.Scatter(\n",
    "        x=df_result.index,\n",
    "        y=df_result.value,\n",
    "        mode=\"lines\",\n",
    "        name=\"values\",\n",
    "        marker=dict(),\n",
    "        text=df_result.index,\n",
    "        line=dict(color=\"rgba(0,0,0, 0.3)\"),\n",
    "    )\n",
    "    data.append(value)\n",
    "\n",
    "#     baseline = go.Scatter(\n",
    "#         x=df_baseline.index,\n",
    "#         y=df_baseline.prediction,\n",
    "#         mode=\"lines\",\n",
    "#         line={\"dash\": \"dot\"},\n",
    "#         name='linear regression',\n",
    "#         marker=dict(),\n",
    "#         text=df_baseline.index,\n",
    "#         opacity=0.8,\n",
    "#     )\n",
    "#     data.append(baseline)\n",
    "    \n",
    "    prediction = go.Scatter(\n",
    "        x=df_result.index,\n",
    "        y=df_result.prediction,\n",
    "        mode=\"lines\",\n",
    "        line={\"dash\": \"dot\"},\n",
    "        name='predictions',\n",
    "        marker=dict(),\n",
    "        text=df_result.index,\n",
    "        opacity=0.8,\n",
    "    )\n",
    "    data.append(prediction)\n",
    "    \n",
    "    layout = dict(\n",
    "        title=\"Predictions vs Actual Values for the dataset\",\n",
    "        xaxis=dict(title=\"Time\", ticklen=5, zeroline=False),\n",
    "        yaxis=dict(title=\"Value\", ticklen=5, zeroline=False),\n",
    "    )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "    \n",
    "    \n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "plot_predictions(df_result, df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(self, X, y, batch_size=1, n_features=1, n_steps=100):\n",
    "        predictions1 = []\n",
    "        \n",
    "        test_loader_iter = iter(test_loader)\n",
    "        *_, (X, y) = test_loader_iter\n",
    "        y = y.to(device).detach().numpy()\n",
    "        X = X.view([batch_size, -1, n_features]).to(device)\n",
    "        X = torch.roll(X, shifts=1, dims=2)\n",
    "        X[..., -1, 0] = y.item(0)\n",
    "             \n",
    "        with torch.no_grad():\n",
    "            self.model.eval()\n",
    "            for _ in range(n_steps):\n",
    "                X = X.view([batch_size, -1, n_features]).to(device)\n",
    "                yhat = self.model(X)\n",
    "                yhat = yhat.to(device).detach().numpy()\n",
    "                X = torch.roll(X, shifts=1, dims=2)\n",
    "                X[..., -1, 0] = yhat.item(0)\n",
    "                predictions1.append(yhat.item(0))\n",
    "\n",
    "        return predictions1\n",
    "\n",
    "test_loader_iter = iter(test_loader)\n",
    "*_, X, y = test_loader_iter\n",
    "forecast(X, y,  batch_size=batch_size, n_features=input_dim, n_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdf154",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_prediction = 20\n",
    "#start the predcition from last time point +1\n",
    "prediction_dates = pd.date_range(\"2021-07-31\", periods=num_prediction, freq=\"D\").tolist()\n",
    "series_column = pd.DataFrame(prediction_dates, columns= [\"Entered on\"])\n",
    "series = series_column.set_index(\"Entered on\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a53dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_features = (\n",
    "                series       \n",
    "                .assign(month = series.index.month)\n",
    "                .assign(day_of_week = series.index.dayofweek)\n",
    "                .assign(week_of_year = series.index.week))\n",
    "series_features = onehot_encode_pd(series_features, [\"month\",\"day_of_week\",'week_of_year'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f60d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cyclical_features(df, col_name, period, start_num=0):\n",
    "    kwargs = {\n",
    "        f'sin_{col_name}' : lambda x: np.sin(2*np.pi*(df[col_name]-start_num)/period),\n",
    "        f'cos_{col_name}' : lambda x: np.cos(2*np.pi*(df[col_name]-start_num)/period)    \n",
    "             }\n",
    "    return df.assign(**kwargs).drop(columns=[col_name])\n",
    "\n",
    "# df_features = generate_cyclical_features(df_features, 'hour', 24, 0)\n",
    "# df_features = generate_cyclical_features(df_features, 'day_of_week', 7, 0)\n",
    "# df_features = generate_cyclical_features(df_features, 'month', 12, 1)\n",
    "# series_features = generate_cyclical_features(series_features, 'week_of_year', 52, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d7a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_label_split(df, index):\n",
    "    y = series_column[[\"Entered on\"]]\n",
    "    X = df\n",
    "    return X, y\n",
    "X, y = feature_label_split(series_features, series.index)\n",
    "scaler = get_scaler('minmax')\n",
    "X = scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y)\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "test_features = torch.Tensor(X)\n",
    "test_targets = torch.Tensor(y)\n",
    "\n",
    "\n",
    "test = TensorDataset(test_targets, test_features)\n",
    "\n",
    "test_loader_forecast = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8dd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(series_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcc68d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_loader_iter = iter(test_loader_forecast)\n",
    "# *_, (X, y) = test_loader_iter\n",
    "\n",
    "predictions2 = forecast_features(test_loader_features, \n",
    "                                 batch_size=1, \n",
    "                                 n_features=len(series_features.columns)\n",
    "                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d16158",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a310d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6edd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform into readbale format\n",
    "vals = np.concatenate(values, axis=0).ravel()\n",
    "preds = np.concatenate(predictions, axis=0).ravel()\n",
    "#make a DF\n",
    "df_result = pd.DataFrame(data={\"value\": vals, \"prediction\": preds}, index=X_test.head(len(vals)).index)\n",
    "df_result = df_result.sort_index()\n",
    "# df_result = inverse_transform(scaler, df_result, [[\"value\", \"prediction\"]])\n",
    "\n",
    "#create DF for new time\n",
    "num_prediction = 30\n",
    "#start the predcition from last time point +1\n",
    "prediction_dates = pd.date_range(\"2021-07-30\", periods=num_prediction, freq=\"D\").tolist()\n",
    "series = pd.DataFrame(prediction_dates, columns= [\"Entered on\"])\n",
    "# put the new tile line with predictions\n",
    "preds = np.stack(predictions1)\n",
    "# preds = np.concatenate(predictions1, axis=0).ravel()\n",
    "\n",
    "forecast1 = pd.DataFrame(preds, columns=['future'])\n",
    "df = pd.concat([series, forecast1], axis=1)\n",
    "df = df.set_index(df[\"Entered on\"])\n",
    "future = df.drop(columns = [\"Entered on\"])\n",
    "\n",
    "   \n",
    "\n",
    "#concat both values\n",
    "result = pd.concat([df_result[\"value\"], df[\"future\"], df_result[\"prediction\"]], axis=1)\n",
    "result = inverse_transform(scaler, result, [[\"value\", \"future\", \"prediction\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae41a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "\n",
    "def plot_predictions(df_result, df_baseline):\n",
    "    data = []\n",
    "    \n",
    "    value = go.Scatter(\n",
    "        x= result.index,\n",
    "        y= result.value,\n",
    "        mode=\"lines\",\n",
    "        name=\"values\",\n",
    "        marker=dict(),\n",
    "        text=df_result.index,\n",
    "        line=dict(color=\"rgba(0,0,0, 0.3)\"),\n",
    "    )\n",
    "    data.append(value)\n",
    "    \n",
    "    future= go.Scatter(\n",
    "        x= result.index,\n",
    "        y= result.future,\n",
    "        mode=\"lines\",\n",
    "        name=\"future\",\n",
    "        marker=dict(),\n",
    "        text=df_result.index,\n",
    "        \n",
    "    )\n",
    "    data.append(future)\n",
    "\n",
    "\n",
    "    \n",
    "    prediction = go.Scatter(\n",
    "        x= result.index,\n",
    "        y= result.prediction,\n",
    "        mode=\"lines\",\n",
    "        line={\"dash\": \"dot\"},\n",
    "        name='predictions',\n",
    "        marker=dict(),\n",
    "        text=df_result.index,\n",
    "        opacity=0.8,\n",
    "    )\n",
    "    data.append(prediction)\n",
    "    \n",
    "    layout = dict(\n",
    "        title=\"Forecast the future\",\n",
    "        xaxis=dict(title=\"Time\", ticklen=5, zeroline=False),\n",
    "        yaxis=dict(title=\"Value\", ticklen=5, zeroline=False),\n",
    "    )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "    \n",
    "    \n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "plot_predictions(df_result, df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7fead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def calculate_metrics(df):\n",
    "    result_metrics = {'mae' : mean_absolute_error(df.value, df.prediction),\n",
    "                      'rmse' : mean_squared_error(df.value, df.prediction) ** 0.5,\n",
    "                      'r2' : r2_score(df.value, df.prediction)}\n",
    "    \n",
    "    print(\"Mean Absolute Error:       \", result_metrics[\"mae\"])\n",
    "    print(\"Root Mean Squared Error:   \", result_metrics[\"rmse\"])\n",
    "    print(\"R^2 Score:                 \", result_metrics[\"r2\"])\n",
    "    return result_metrics\n",
    "\n",
    "result_metrics = calculate_metrics(df_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca547f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# def build_baseline_model(df, test_ratio, target_col):\n",
    "#     X, y = feature_label_split(df, target_col)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=test_ratio, shuffle=False\n",
    "#     )\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(X_train, y_train)\n",
    "#     prediction = model.predict(X_test)\n",
    "\n",
    "#     result = pd.DataFrame(y_test)\n",
    "#     result[\"prediction\"] = prediction\n",
    "#     result = result.sort_index()\n",
    "\n",
    "#     return result\n",
    "\n",
    "# df_baseline = build_baseline_model(df_features, 0.2, 'value')\n",
    "# baseline_metrics = calculate_metrics(df_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ce7f06",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "\n",
    "\n",
    "def plot_predictions(df_result, df_baseline):\n",
    "    data = []\n",
    "    \n",
    "    value = go.Scatter(\n",
    "        x=df_result.index,\n",
    "        y=df_result.value,\n",
    "        mode=\"lines\",\n",
    "        name=\"values\",\n",
    "        marker=dict(),\n",
    "        text=df_result.index,\n",
    "        line=dict(color=\"rgba(0,0,0, 0.3)\"),\n",
    "    )\n",
    "    data.append(value)\n",
    "\n",
    "#     baseline = go.Scatter(\n",
    "#         x=df_baseline.index,\n",
    "#         y=df_baseline.prediction,\n",
    "#         mode=\"lines\",\n",
    "#         line={\"dash\": \"dot\"},\n",
    "#         name='linear regression',\n",
    "#         marker=dict(),\n",
    "#         text=df_baseline.index,\n",
    "#         opacity=0.8,\n",
    "#     )\n",
    "#     data.append(baseline)\n",
    "    \n",
    "    prediction = go.Scatter(\n",
    "        x=df_result.index,\n",
    "        y=df_result.prediction,\n",
    "        mode=\"lines\",\n",
    "        line={\"dash\": \"dot\"},\n",
    "        name='predictions',\n",
    "        marker=dict(),\n",
    "        text=df_result.index,\n",
    "        opacity=0.8,\n",
    "    )\n",
    "    data.append(prediction)\n",
    "    \n",
    "    layout = dict(\n",
    "        title=\"Predictions vs Actual Values for the dataset\",\n",
    "        xaxis=dict(title=\"Time\", ticklen=5, zeroline=False),\n",
    "        yaxis=dict(title=\"Value\", ticklen=5, zeroline=False),\n",
    "    )\n",
    "\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    iplot(fig)\n",
    "    \n",
    "    \n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "plot_predictions(df_result, df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099cb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(df_result, df_baseline):\n",
    "    data = []\n",
    "    \n",
    "    value = go.Scatter(\n",
    "        x=df_result.index,\n",
    "        y=df_result.value,\n",
    "        mode='lines',\n",
    "        line= dict(color=\"rgba(1,0,1, 0.3)\",\n",
    "                  width=1.5))\n",
    "       \n",
    "        \n",
    "        \n",
    "    \n",
    "    data.append(value)\n",
    "\n",
    "    prediction = go.Scatter(\n",
    "        x=df_result.index,\n",
    "        y=df_result.prediction,\n",
    "        mode=\"lines\",\n",
    "        line=dict(width=1.5, dash=\"dashdot\"))\n",
    "    \n",
    "    \n",
    "    data.append(prediction)\n",
    "    \n",
    "    frames = [dict(data= [dict(type='scatter',\n",
    "                           x=df_result.index, \n",
    "                               y=df_result.value),\n",
    "                          dict(type='scatter',\n",
    "                           x=df_result.index, \n",
    "                               y=df_result.prediction[:k+1])],\n",
    "               traces= [0,1],  \n",
    "              )for k  in  range(1, len(df_result)-1)]\n",
    "    layout = go.Layout(title=\"Predictions vs Actual Values for the dataset\",\n",
    "        xaxis=dict(title=\"Time\", ticklen=5, zeroline=False),\n",
    "        yaxis=dict(title=\"Value\", ticklen=5, zeroline=False),\n",
    "                       width=900,\n",
    "                   height=600,\n",
    "                   showlegend=False,\n",
    "                   hovermode='x unified',\n",
    "                   updatemenus=[\n",
    "                        dict(\n",
    "                            type='buttons', showactive=False,\n",
    "                            y=1.05,\n",
    "                            x=1.15,\n",
    "                            xanchor='right',\n",
    "                            yanchor='top',\n",
    "                            pad=dict(t=0, r=10),\n",
    "                            buttons=[dict(label='Play',\n",
    "                            method='animate',\n",
    "                            args=[None, \n",
    "                                  dict(frame=dict(duration=0, \n",
    "                                                  redraw=False),\n",
    "    transition=dict(duration=0),\n",
    "                                                  fromcurrent=True,\n",
    "                                                  mode='immediate')]\n",
    "                            )]\n",
    "                        ),\n",
    "                        \n",
    "                    ]              \n",
    "                  )\n",
    "    layout.update(xaxis =dict(range=[df_result.index[0], df_result.index[-1]], autorange=False),\n",
    "                  yaxis =dict(range=[0, max(df_result.prediction)], autorange=False));\n",
    "    fig = go.Figure(data=[value, prediction], frames=frames, layout=layout)\n",
    "    fig.show()\n",
    "    import plotly.express as px\n",
    "    fig.write_html(\"Animation.html\")\n",
    "\n",
    "    \n",
    "pyo.init_notebook_mode()\n",
    "plot_predictions(df_result, df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db6cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d9766f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0caf28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytrch]",
   "language": "python",
   "name": "conda-env-pytrch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
